{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Давайте строить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>TEMP_Count</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>DEWP_Count</th>\n",
       "      <th>SLP</th>\n",
       "      <th>SLP_Count</th>\n",
       "      <th>STP</th>\n",
       "      <th>STP_Count</th>\n",
       "      <th>VISIB</th>\n",
       "      <th>...</th>\n",
       "      <th>MAX_is_missing</th>\n",
       "      <th>MIN_is_missing</th>\n",
       "      <th>PRCP_is_missing</th>\n",
       "      <th>SNDP_is_missing</th>\n",
       "      <th>Is_Fog</th>\n",
       "      <th>Is_Rain or Drizzle</th>\n",
       "      <th>Is_Snow or Ice Pellets</th>\n",
       "      <th>Is_Hail</th>\n",
       "      <th>Is_Thunder</th>\n",
       "      <th>Is_Tornado or Funnel Cloud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1936-12-31</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1937-01-01</td>\n",
       "      <td>33.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1937-01-02</td>\n",
       "      <td>28.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1937-01-03</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1937-01-04</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  TEMP  TEMP_Count    DEWP  DEWP_Count     SLP  SLP_Count  \\\n",
       "0  1936-12-31  16.0         4.0  9999.9         0.0  1022.9        4.0   \n",
       "1  1937-01-01  33.5         4.0  9999.9         0.0  1020.9        4.0   \n",
       "2  1937-01-02  28.8         4.0  9999.9         0.0  1020.4        4.0   \n",
       "3  1937-01-03  29.0         4.0  9999.9         0.0  1013.2        4.0   \n",
       "4  1937-01-04  30.0         4.0  9999.9         0.0  1013.2        4.0   \n",
       "\n",
       "      STP  STP_Count  VISIB            ...              MAX_is_missing  \\\n",
       "0  9999.9        0.0    3.0            ...                           0   \n",
       "1  9999.9        0.0    2.5            ...                           0   \n",
       "2  9999.9        0.0    4.0            ...                           0   \n",
       "3  9999.9        0.0    2.5            ...                           0   \n",
       "4  9999.9        0.0    2.2            ...                           0   \n",
       "\n",
       "   MIN_is_missing  PRCP_is_missing  SNDP_is_missing  Is_Fog  \\\n",
       "0               0                0                1       0   \n",
       "1               0                0                1       0   \n",
       "2               0                0                1       0   \n",
       "3               0                0                1       0   \n",
       "4               0                0                1       0   \n",
       "\n",
       "   Is_Rain or Drizzle  Is_Snow or Ice Pellets  Is_Hail  Is_Thunder  \\\n",
       "0                   0                       0        0           0   \n",
       "1                   1                       0        0           0   \n",
       "2                   0                       0        0           0   \n",
       "3                   1                       1        0           0   \n",
       "4                   0                       1        0           0   \n",
       "\n",
       "  Is_Tornado or Funnel Cloud  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"data/Moscow_weather_preparsed.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>TEMP_Count</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>DEWP_Count</th>\n",
       "      <th>SLP</th>\n",
       "      <th>SLP_Count</th>\n",
       "      <th>VISIB</th>\n",
       "      <th>VISIB_Count</th>\n",
       "      <th>WDSP</th>\n",
       "      <th>...</th>\n",
       "      <th>MAX_is_missing</th>\n",
       "      <th>MIN_is_missing</th>\n",
       "      <th>PRCP_is_missing</th>\n",
       "      <th>SNDP_is_missing</th>\n",
       "      <th>Is_Fog</th>\n",
       "      <th>Is_Rain or Drizzle</th>\n",
       "      <th>Is_Snow or Ice Pellets</th>\n",
       "      <th>Is_Hail</th>\n",
       "      <th>Is_Thunder</th>\n",
       "      <th>Is_Tornado or Funnel Cloud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1936-12-31</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1937-01-01</td>\n",
       "      <td>33.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1937-01-02</td>\n",
       "      <td>28.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>999.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1937-01-03</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1937-01-04</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  TEMP  TEMP_Count    DEWP  DEWP_Count     SLP  SLP_Count  VISIB  \\\n",
       "0  1936-12-31  16.0         4.0  9999.9         0.0  1022.9        4.0    3.0   \n",
       "1  1937-01-01  33.5         4.0  9999.9         0.0  1020.9        4.0    2.5   \n",
       "2  1937-01-02  28.8         4.0  9999.9         0.0  1020.4        4.0    4.0   \n",
       "3  1937-01-03  29.0         4.0  9999.9         0.0  1013.2        4.0    2.5   \n",
       "4  1937-01-04  30.0         4.0  9999.9         0.0  1013.2        4.0    2.2   \n",
       "\n",
       "   VISIB_Count   WDSP             ...              MAX_is_missing  \\\n",
       "0          4.0    9.0             ...                           0   \n",
       "1          4.0   13.0             ...                           0   \n",
       "2          4.0  999.9             ...                           0   \n",
       "3          4.0   17.0             ...                           0   \n",
       "4          4.0   13.3             ...                           0   \n",
       "\n",
       "   MIN_is_missing  PRCP_is_missing  SNDP_is_missing  Is_Fog  \\\n",
       "0               0                0                1       0   \n",
       "1               0                0                1       0   \n",
       "2               0                0                1       0   \n",
       "3               0                0                1       0   \n",
       "4               0                0                1       0   \n",
       "\n",
       "   Is_Rain or Drizzle  Is_Snow or Ice Pellets  Is_Hail  Is_Thunder  \\\n",
       "0                   0                       0        0           0   \n",
       "1                   1                       0        0           0   \n",
       "2                   0                       0        0           0   \n",
       "3                   1                       1        0           0   \n",
       "4                   0                       1        0           0   \n",
       "\n",
       "   Is_Tornado or Funnel Cloud  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = raw_data.drop(columns=['STP', 'STP_Count', 'MAX_Flag', 'MIN_Flag', 'PRCP_Flag'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_features = list(data.columns[-6:])\n",
    "# попробуем оставить только адекватные фичи\n",
    "# все Count скорее всего можно игнорировать\n",
    "# пропущенные значения и так достаточно отделены от возможных данных\n",
    "# work_features = [\"TEMP\", \"DEWP\", \"SLP\", \"VISIB\", \"WDSP\", \"MXSPD\", \"GUST\", \"MAX\", \"MIN\", \"PRCP\", \"SNDP\"]\n",
    "work_features = [\"TEMP\", \"DEWP\", \"SLP\", \"VISIB\", \"WDSP\", \"MXSPD\", \"GUST\", \"MAX\", \"MIN\", \"PRCP\", \"SNDP\"]\n",
    "# work_features += [s + \"_is_missing\" for s in work_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# давайте учитывать данные до 3 дней в прошлое\n",
    "max_days_back = 3\n",
    "data_prev = {}\n",
    "goal = data[goal_features]\n",
    "cur_data = data[work_features]\n",
    "cur_res = pd.DataFrame(index=data.index)\n",
    "data_size = data.shape[0]\n",
    "for i in range(1, max_days_back + 1):\n",
    "    # индексы - боль\n",
    "    cur_data = cur_data.drop(index=cur_data.index[-1]).set_index(np.arange(data_size - i))\n",
    "    goal = goal.drop(index=goal.index[0]).set_index(np.arange(data_size - i))\n",
    "    cur_res = cur_res.drop(index=cur_res.index[0]).set_index(np.arange(data_size - i))\n",
    "    for feature in work_features:\n",
    "        cur_res[\"{} {} day(s) ago\".format(feature, i)] = cur_data[feature]\n",
    "    data_prev[i] = (cur_res, goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMP 1 day(s) ago</th>\n",
       "      <th>TEMP 2 day(s) ago</th>\n",
       "      <th>TEMP 3 day(s) ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.8</td>\n",
       "      <td>33.5</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>28.8</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEMP 1 day(s) ago  TEMP 2 day(s) ago  TEMP 3 day(s) ago\n",
       "0               28.8               33.5               16.0\n",
       "1               29.0               28.8               33.5\n",
       "2               30.0               29.0               28.8\n",
       "3               28.0               30.0               29.0\n",
       "4               26.5               28.0               30.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prev[3][0][[\"TEMP 1 day(s) ago\", \"TEMP 2 day(s) ago\", \"TEMP 3 day(s) ago\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      "0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "\n",
      "0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0\n",
      "0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0\n",
      "0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0\n"
     ]
    }
   ],
   "source": [
    "print(*list(data_prev[1][1][\"Is_Rain or Drizzle\"][:50]))\n",
    "print(*list(data_prev[2][1][\"Is_Rain or Drizzle\"][:50]))\n",
    "print(*list(data_prev[3][1][\"Is_Rain or Drizzle\"][:50]))\n",
    "print()\n",
    "print(*list(data_prev[1][1][\"Is_Rain or Drizzle\"][-50:]))\n",
    "print(*list(data_prev[2][1][\"Is_Rain or Drizzle\"][-50:]))\n",
    "print(*list(data_prev[3][1][\"Is_Rain or Drizzle\"][-50:]))\n",
    "\n",
    "# выглядит адекватно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь можно попробовать разные модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(*data_prev[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    17106\n",
       "Name: Is_Tornado or Funnel Cloud, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[\"Is_Tornado or Funnel Cloud\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# не было ещё у нас в Москве торнадо, можно выкинуть\n",
    "goal_features = goal_features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поскольку разбиваем на 2 класса, score - просто доля правильных ответов\n",
    "\n",
    "def test_clfs(X, y, goal_features, clfs, names, verbose=False):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    bests = []\n",
    "    for goal in goal_features:\n",
    "        if verbose:\n",
    "            print(\"Predicting {}:\".format(goal))\n",
    "        goal_train, goal_test = y_train[goal], y_test[goal]\n",
    "        best = (-1, None)\n",
    "        for clf, name in zip(clfs, names):\n",
    "            if verbose:\n",
    "                print(\"{}:\".format(name))\n",
    "            clf.fit(X_train, goal_train)\n",
    "            score = clf.score(X_test, goal_test)\n",
    "            max_class = np.max(goal_train.value_counts() / goal_train.shape[0])\n",
    "            if score >= best[0]:\n",
    "                best = (score, goal, name, clf)\n",
    "            if verbose:\n",
    "                print(\"max class: {}\".format(max_class))\n",
    "                print(\"score: {} ({})\".format(score, \"OK\" if score > max_class else \"BAD\"))\n",
    "                print(\"-------------------------------------------------------------\")\n",
    "        bests.append(best)\n",
    "        if verbose:\n",
    "            print(\"#############################################################\")\n",
    "    return bests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [LogisticRegression(random_state=123), LinearSVC(random_state=123),\n",
    "        BernoulliNB(), DecisionTreeClassifier(random_state=123)]\n",
    "names = [\"Log reg\", \"Lin SVM\", \"Bayes (bernoulli)\", \"Decision tree\"]\n",
    "\n",
    "bests = test_clfs(*data_prev[1], goal_features, clfs, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.97790636507101525,\n",
       "  'Is_Fog',\n",
       "  'Log reg',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=123, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False)),\n",
       " (0.68683149219708928,\n",
       "  'Is_Rain or Drizzle',\n",
       "  'Bayes (bernoulli)',\n",
       "  BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)),\n",
       " (0.81483429773803262,\n",
       "  'Is_Snow or Ice Pellets',\n",
       "  'Decision tree',\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
       "              splitter='best')),\n",
       " (0.99491495704015431,\n",
       "  'Is_Hail',\n",
       "  'Bayes (bernoulli)',\n",
       "  BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)),\n",
       " (0.95511134490618976,\n",
       "  'Is_Thunder',\n",
       "  'Bayes (bernoulli)',\n",
       "  BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bests\n",
    "#Пока что наивный байес работает лучше всех"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим ансамблей\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "clfs = [LogisticRegression(random_state=123), BernoulliNB(), RandomForestClassifier(random_state=123)]\n",
    "names = [\"Log reg\", \"Bayes (bernoulli)\", \"Random forest\"]\n",
    "\n",
    "bests = test_clfs(*data_prev[3], goal_features, clfs, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.97334268677656965,\n",
       "  'Is_Fog',\n",
       "  'Random forest',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "              oob_score=False, random_state=123, verbose=0, warm_start=False)),\n",
       " (0.69344089793055064,\n",
       "  'Is_Rain or Drizzle',\n",
       "  'Random forest',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "              oob_score=False, random_state=123, verbose=0, warm_start=False)),\n",
       " (0.84128376008418104,\n",
       "  'Is_Snow or Ice Pellets',\n",
       "  'Random forest',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "              oob_score=False, random_state=123, verbose=0, warm_start=False)),\n",
       " (0.99438793405822523,\n",
       "  'Is_Hail',\n",
       "  'Random forest',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "              oob_score=False, random_state=123, verbose=0, warm_start=False)),\n",
       " (0.96124166958961765,\n",
       "  'Is_Thunder',\n",
       "  'Bayes (bernoulli)',\n",
       "  BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bests\n",
    "# случайный лес ещё лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "clfs = [RandomForestClassifier(random_state=123),\n",
    "        AdaBoostClassifier(LogisticRegression(random_state=123), n_estimators=5, random_state=123),\n",
    "        BernoulliNB(), AdaBoostClassifier(DecisionTreeClassifier(max_depth=5), random_state=123)]\n",
    "names = [\"Random forest\", \"Log reg (boosted)\", \"Bayes (bernoulli, boosted)\", \"Decision tree (boosted)\"]\n",
    "\n",
    "bests = test_clfs(*data_prev[3], goal_features, clfs, names)\n",
    "# байес умирает после бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.97790249035426169,\n",
       "  'Is_Fog',\n",
       "  'Random forest',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "              oob_score=False, random_state=123, verbose=0, warm_start=False)),\n",
       " (0.70641880042090499,\n",
       "  'Is_Rain or Drizzle',\n",
       "  'Random forest',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "              oob_score=False, random_state=123, verbose=0, warm_start=False)),\n",
       " (0.83602244826376715,\n",
       "  'Is_Snow or Ice Pellets',\n",
       "  'Random forest',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "              oob_score=False, random_state=123, verbose=0, warm_start=False)),\n",
       " (0.99386180287618375,\n",
       "  'Is_Hail',\n",
       "  'Decision tree (boosted)',\n",
       "  AdaBoostClassifier(algorithm='SAMME.R',\n",
       "            base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "              splitter='best'),\n",
       "            learning_rate=1.0, n_estimators=50, random_state=123)),\n",
       " (0.96246930901438088,\n",
       "  'Is_Thunder',\n",
       "  'Bayes (bernoulli, boosted)',\n",
       "  BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь оптимизируем параметры оптимальных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 10s\n",
      "{'max_depth': 7, 'n_estimators': 80}\n",
      "0.854268052085\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "params = {'n_estimators': [40, 50, 60, 70, 80], \n",
    "          'max_depth': list(range(2, 9))}\n",
    "\n",
    "#optimiser = RandomizedSearchCV(RandomForestClassifier(), params, refit=False, n_iter=10)\n",
    "optimiser = GridSearchCV(RandomForestClassifier(random_state=123), params, refit=False)\n",
    "X, y = data_prev[1]\n",
    "%time optimiser.fit(X, y[\"Is_Snow or Ice Pellets\"])\n",
    "print(optimiser.best_params_)\n",
    "print(optimiser.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimising Is_Fog:\n",
      "Wall time: 1min 8s\n",
      "Params: {'max_depth': 2, 'n_estimators': 90}\n",
      "Best score: 0.900381461832\n",
      "#############################################################\n",
      "Optimising Is_Rain or Drizzle:\n",
      "Wall time: 1min 51s\n",
      "Params: {'max_depth': 8, 'n_estimators': 50}\n",
      "Best score: 0.708905160696\n",
      "#############################################################\n",
      "Optimising Is_Snow or Ice Pellets:\n",
      "Wall time: 1min 42s\n",
      "Params: {'max_depth': 8, 'n_estimators': 70}\n",
      "Best score: 0.851756039812\n",
      "#############################################################\n",
      "Optimising Is_Hail:\n",
      "Wall time: 18.3 s\n",
      "Params: {'max_depth': 3, 'n_estimators': 5}\n",
      "Best score: 0.993817687552\n",
      "#############################################################\n",
      "Optimising Is_Thunder:\n",
      "Wall time: 29.3 s\n",
      "Params: {'max_depth': 8, 'n_estimators': 20}\n",
      "Best score: 0.959836892182\n",
      "#############################################################\n"
     ]
    }
   ],
   "source": [
    "# при кросс-валидации случайный лес оказывается всё-таки лучше всех\n",
    "clfs = [RandomForestClassifier(random_state=123),\n",
    "        RandomForestClassifier(random_state=123),\n",
    "        RandomForestClassifier(random_state=123),\n",
    "        RandomForestClassifier(random_state=123),\n",
    "        RandomForestClassifier(random_state=123)]\n",
    "clf_params = [{'n_estimators': list(range(50, 100, 10)), \n",
    "               'max_depth': list(range(2, 5)) + [None]},\n",
    "\n",
    "              {'n_estimators': list(range(30, 80, 10)), \n",
    "               'max_depth': list(range(5, 10)) + [None]},\n",
    "\n",
    "              {'n_estimators': list(range(30, 80, 10)), \n",
    "               'max_depth': list(range(5, 10)) + [None]},\n",
    "\n",
    "              {'n_estimators': list(range(5, 30, 5)), \n",
    "               'max_depth': list(range(3, 7)) + [None]},\n",
    "\n",
    "              {'n_estimators': list(range(5, 30, 5)), \n",
    "               'max_depth': list(range(5, 10)) + [None]}]\n",
    "\n",
    "X, y = data_prev[3]\n",
    "bests = []\n",
    "for goal, clf, params in zip(goal_features, clfs, clf_params):\n",
    "    print(\"Optimising {}:\".format(goal))\n",
    "    y_goal = y[goal]\n",
    "    optimiser = GridSearchCV(clf, params, refit=False)\n",
    "    %time optimiser.fit(X, y_goal)\n",
    "    print(\"Params:\", optimiser.best_params_)\n",
    "    print(\"Best score:\", optimiser.best_score_)\n",
    "    bests.append((optimiser.best_params_, optimiser.best_score_))\n",
    "    print(\"#############################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'max_depth': 2, 'n_estimators': 90}, 0.90038146183189371),\n",
       " ({'max_depth': 8, 'n_estimators': 50}, 0.7089051606962774),\n",
       " ({'max_depth': 8, 'n_estimators': 70}, 0.85175603981233827),\n",
       " ({'max_depth': 3, 'n_estimators': 5}, 0.99381768755206734),\n",
       " ({'max_depth': 8, 'n_estimators': 20}, 0.95983689218222479)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9743499802692156,\n",
       " 0.68290437146490113,\n",
       " 0.71587670452054197,\n",
       " 0.99381768755206734,\n",
       " 0.95974919980707674]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_data = data_prev[3][1]\n",
    "randoms = [np.max(np.max(goal_data[goal].value_counts() / goal_data[goal].shape[0])) for goal in goal_features]\n",
    "randoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного лучше тупого нерандома; score для тумана возможно пострадал из-за кросс-валидации, т.к. для базового случайного леса было при одинарном разбиении выборки было 0.97790249035426169, а если train в разбиении почти не содержит единиц, может быть достаточно плохо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
